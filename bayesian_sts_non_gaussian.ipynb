{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting to go further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "#from matplotlib import pylab as plot\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import tensorflow.compat.v2 as tf\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import bijectors as tfb\n",
    "\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow_probability import sts\n",
    "\n",
    "#tf.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.)\n",
    "sns.set_style(\"whitegrid\")\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('C:/Users/amaur/Documents/Data_science/Bayesian_TS/h1weekly.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Date'] = pd.to_datetime(raw_data['Date'])\n",
    "\n",
    "# Calculate min and max date\n",
    "min_date = raw_data['Date'].min()\n",
    "max_date = raw_data['Date'].max()\n",
    "\n",
    "# Generate weekly interval using pandas date_range\n",
    "weekly_dates = pd.date_range(start=min_date, end=max_date, freq='W')\n",
    "\n",
    "# Convert the pandas DatetimeIndex to a numpy.ndarray with datetime64 type\n",
    "cancelation_dates = weekly_dates.to_numpy(dtype=np.datetime64)\n",
    "cancelation_dates = cancelation_dates.astype('datetime64[W]')\n",
    "\n",
    "## date printing formater \n",
    "cancelation_loc = mdates.DayLocator(interval=31)\n",
    "cancelation_fmt = mdates.DateFormatter('%Y-%m')\n",
    "\n",
    "## Number of forcasting steps (half a year)\n",
    "num_forecast_steps = 26\n",
    "\n",
    "## Formating time serie data\n",
    "serial_data = raw_data.IsCanceled.tolist()\n",
    "serial_data = np.array(serial_data).astype(np.float32)\n",
    "## Training_data\n",
    "training_data = serial_data[:-num_forecast_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=62))\n",
    "plt.plot(raw_data.Date, raw_data.IsCanceled)\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_raw_data = raw_data.set_index('Date')\n",
    "indexed_raw_data.index.freq = 'W'\n",
    "decomposition = seasonal_decompose(indexed_raw_data['IsCanceled'], model='additive')\n",
    "plt.figure(figsize=(10, 8))\n",
    "decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf,confidence_interval=sm.tsa.acf(serial_data, nlags=20 ,alpha=0.05, fft=False)\n",
    "plot_acf(serial_data, lags=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacf,confidence_interval=sm.tsa.pacf(serial_data, nlags=20 ,alpha=0.05)\n",
    "plot_pacf(serial_data, lags=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_bijector = tfb.Exp()\n",
    "# Transform data for halfnormal bijection\n",
    "approximate_unconstrained_rates_train = positive_bijector.inverse(tf.convert_to_tensor(training_data))\n",
    "approximate_unconstrained_rates_serial = positive_bijector.inverse(tf.convert_to_tensor(serial_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = 89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(approximate_unconstrained_rates, ar, ma):\n",
    "  trend = sts.LocalLinearTrend(observed_time_series=approximate_unconstrained_rates)\n",
    "  #seasonal_semester = tfp.sts.Seasonal(num_seasons=4, num_steps_per_season = 13, observed_time_series=observed_time_series,\n",
    "  #name = 'semester variation')\n",
    "  monthly_effect = tfp.sts.Seasonal(num_seasons=52, observed_time_series=approximate_unconstrained_rates,\n",
    "  name = 'infra month variation')\n",
    "  arma = tfp.sts.AutoregressiveIntegratedMovingAverage(ar_order=ar, ma_order=ma, observed_time_series=approximate_unconstrained_rates)\n",
    "  return tfp.sts.Sum([trend, monthly_effect, arma], observed_time_series=approximate_unconstrained_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_model = build_model(approximate_unconstrained_rates_train, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sts_with_LogNormal_likelihood_model():\n",
    "  # Encode the parameters of the STS model as random variables.\n",
    "  param_vals = []\n",
    "  for param in sts_model.parameters:\n",
    "    param_val = yield param.prior\n",
    "    param_vals.append(param_val)\n",
    "\n",
    "  # Use the STS model to encode the log- (or inverse-softplus)\n",
    "  # rate of a LogNormal.\n",
    "  unconstrained_rate = yield sts_model.make_state_space_model(num_timesteps, param_vals)\n",
    "  rate = positive_bijector.forward(unconstrained_rate[..., 0])\n",
    "  observed_counts = yield tfd.LogNormal(loc = serial_data.mean(), scale=serial_data.std(), name='observed_cancelation')\n",
    "\n",
    "model = tfd.JointDistributionCoroutineAutoBatched(sts_with_LogNormal_likelihood_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinned_model = model.experimental_pin(observed_cancelation=training_data)\n",
    "constraining_bijector = pinned_model.experimental_default_event_space_bijector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_posterior = tfp.experimental.vi.build_factored_surrogate_posterior(event_shape=pinned_model.event_shape,\n",
    "    bijector=constraining_bijector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinned_model.event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow external control of optimization to reduce test runtimes.\n",
    "num_variational_steps = 200 # @param { isTemplate: true}\n",
    "num_variational_steps = int(num_variational_steps)\n",
    "\n",
    "losses = tfp.vi.fit_surrogate_posterior(pinned_model.unnormalized_log_prob,\n",
    "                                        surrogate_posterior,\n",
    "                                        optimizer=tf.optimizers.Adam(0.1),\n",
    "                                        num_steps=num_variational_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.title(\"Variational loss\")\n",
    "_ = plt.xlabel(\"Steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = np.log(serial_data.mean())\n",
    "\n",
    "scale = np.log(serial_data.std())/2\n",
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_forecasted_counts(sts_model, posterior_latent_rates,\n",
    "                             posterior_params, num_steps_forecast,\n",
    "                             num_sampled_forecasts):\n",
    "\n",
    "  # Forecast the future latent unconstrained rates, given the inferred latent\n",
    "  # unconstrained rates and parameters.\n",
    "  unconstrained_rates_forecast_dist = tfp.sts.forecast(sts_model,\n",
    "    observed_time_series=unconstrained_rate_samples,\n",
    "    parameter_samples=posterior_params,\n",
    "    num_steps_forecast=num_steps_forecast)\n",
    "\n",
    "  # Transform the forecast to positive-valued Poisson rates.\n",
    "  rates_forecast_dist = tfd.TransformedDistribution(\n",
    "      unconstrained_rates_forecast_dist,\n",
    "      positive_bijector)\n",
    "\n",
    "  # Sample from the forecast model following the chain rule:\n",
    "  # P(counts) = P(counts | latent_rates)P(latent_rates)\n",
    "  sampled_latent_rates = rates_forecast_dist.sample(num_sampled_forecasts)\n",
    "  sampled_forecast_counts = tfd.LogNormal(loc=sampled_latent_rates, scale = 0.001).sample()\n",
    "\n",
    "  return sampled_forecast_counts, sampled_latent_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = surrogate_posterior.sample(89)\n",
    "param_samples = posterior_samples[:-1]\n",
    "unconstrained_rate_samples = posterior_samples[-1][..., 0]\n",
    "rate_samples = positive_bijector.forward(unconstrained_rate_samples)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "mean_lower, mean_upper = np.percentile(rate_samples, [10, 90], axis=0)\n",
    "pred_lower, pred_upper = np.percentile(np.random.poisson(rate_samples), \n",
    "                                       [10, 90], axis=0)\n",
    "\n",
    "_ = plt.plot(training_data, color=\"blue\", ls='--', marker='o', label='observed', alpha=0.7)\n",
    "_ = plt.plot(np.mean(rate_samples, axis=0), label='rate', color=\"green\", ls='dashed', lw=2, alpha=0.7)\n",
    "_ = plt.fill_between(np.arange(0, 89), mean_lower, mean_upper, color='green', alpha=0.2)\n",
    "_ = plt.fill_between(np.arange(0, 89), pred_lower, pred_upper, color='grey', label='counts', alpha=0.2)\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"Daily Sample Size\")\n",
    "plt.title(\"Posterior Mean\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lower, pred_upper = np.percentile(np.random.lognormal(mean = np.log(loc), sigma=np.log(scale)), \n",
    "                                       [10, 90], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_samples, rate_samples = sample_forecasted_counts(\n",
    "   sts_model,\n",
    "   posterior_latent_rates=unconstrained_rate_samples,\n",
    "   posterior_params=param_samples,\n",
    "   # Days to forecast:\n",
    "   num_steps_forecast=4,\n",
    "   num_sampled_forecasts=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_samples = np.squeeze(forecast_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast_helper(data, forecast_samples, CI=90):\n",
    "  \"\"\"Plot the observed time series alongside the forecast.\"\"\"\n",
    "  plt.figure(figsize=(10, 4))\n",
    "  forecast_median = np.exp(np.median(forecast_samples, axis=0))\n",
    "\n",
    "  num_steps = len(data)\n",
    "  num_steps_forecast = forecast_median.shape[-1]\n",
    "\n",
    "  plt.plot(np.arange(num_steps), data, lw=2, color='blue', linestyle='--', marker='o',\n",
    "           label='Observed Data', alpha=0.7)\n",
    "\n",
    "  forecast_steps = np.arange(num_steps, num_steps+num_steps_forecast)\n",
    "\n",
    "  CI_interval = [(100 - CI)/2, 100 - (100 - CI)/2]\n",
    "  lower, upper = np.percentile(forecast_samples, CI_interval, axis=0)\n",
    "\n",
    "  plt.plot(forecast_steps, forecast_median, lw=2, ls='--', marker='o', color='orange',\n",
    "           label=str(CI) + '% Forecast Interval', alpha=0.7)\n",
    "  plt.fill_between(forecast_steps,\n",
    "                   lower,\n",
    "                   upper, color='orange', alpha=0.2)\n",
    "\n",
    "  plt.xlim([0, num_steps+num_steps_forecast])\n",
    "  ymin, ymax = min(np.min(forecast_samples), np.min(data)), max(np.max(forecast_samples), np.max(data))\n",
    "  yrange = ymax-ymin\n",
    "  plt.title(\"{}\".format('Observed time series with ' + str(num_steps_forecast) + ' Day Forecast'))\n",
    "  plt.xlabel('Day')\n",
    "  plt.ylabel('Daily Sample Size')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(forecast_samples, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast_helper(training_data, forecast_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bitcoin_prediction_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
